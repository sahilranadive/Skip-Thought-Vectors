{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from model import UniSkip\n",
    "from config import *\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file at ./data/all.txt\n",
      "Making dictionary for these words\n",
      "Using cached dictionary at ./data/all.txt.pkl\n",
      "Making reverse dictionary\n"
     ]
    }
   ],
   "source": [
    "d = DataLoader(\"./data/all.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "mod = UniSkip()\n",
    "print(USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(params=mod.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trail = []\n",
    "last_best_loss = None\n",
    "current_time = datetime.utcnow()\n",
    "\n",
    "def debug(i, loss, prev, nex, prev_pred, next_pred):\n",
    "    global loss_trail\n",
    "    global last_best_loss\n",
    "    global current_time\n",
    "\n",
    "    this_loss = loss.item()\n",
    "    loss_trail.append(this_loss)\n",
    "    loss_trail = loss_trail[-20:]\n",
    "    new_current_time = datetime.utcnow()\n",
    "    time_elapsed = str(new_current_time - current_time)\n",
    "    current_time = new_current_time\n",
    "    print(\"Iteration {}: time = {} last_best_loss = {}, this_loss = {}\".format(\n",
    "              i, time_elapsed, last_best_loss, this_loss))\n",
    "    \n",
    "    print(\"prev = {}\\nnext = {}\\npred_prev = {}\\npred_next = {}\".format(\n",
    "        d.convert_indices_to_sentences(prev),\n",
    "        d.convert_indices_to_sentences(nex),\n",
    "        d.convert_indices_to_sentences(prev_pred),\n",
    "        d.convert_indices_to_sentences(next_pred),\n",
    "    ))\n",
    "    \n",
    "    try:\n",
    "        trail_loss = sum(loss_trail)/len(loss_trail)\n",
    "        if last_best_loss is None or last_best_loss > trail_loss:\n",
    "            print(\"Loss improved from {} to {}\".format(last_best_loss, trail_loss))\n",
    "            \n",
    "            save_loc = \"./saved_models/skip-best\".format(lr, VOCAB_SIZE)\n",
    "            save_loc_encoder = \"./saved_models/encoder-best\".format(lr, VOCAB_SIZE)\n",
    "            print(\"saving model at {}\".format(save_loc)) \n",
    "            torch.save(mod.state_dict(), save_loc) \n",
    "            torch.save(mod.encoder.state_dict(), save_loc_encoder) \n",
    "\n",
    "            last_best_loss = trail_loss\n",
    "    except Exception as e:\n",
    "       print(\"Couldn't save model because {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "0\n",
      "Iteration 0: time = 4:23:12.465433 last_best_loss = 15.418782997131348, this_loss = 16.092342376708984\n",
      "prev = Reaching down, he grabbed her arm and pulled her up and out of the reach of the geese. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "next = The geese kept following. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "pred_prev = She to he said, her arm. and down her into to down of the room. of the car. of of from to to and to and and and and and and and and and and and and and and and\n",
      "pred_next = She driver kept following. out from from from and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-da9be2bb187d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "# a million iterations\n",
    "for i in range(0, 10000):\n",
    "    sentences, lengths = d.fetch_batch(200)\n",
    "\n",
    "    loss, prev, nex, prev_pred, next_pred  = mod(sentences, lengths)\n",
    "   \n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "        debug(i, loss, prev, nex, prev_pred, next_pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditi/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([200, 1200])\n",
      "1\n",
      "torch.Size([200, 1200])\n",
      "2\n",
      "torch.Size([200, 1200])\n",
      "3\n",
      "torch.Size([200, 1200])\n",
      "4\n",
      "torch.Size([200, 1200])\n",
      "5\n",
      "torch.Size([200, 1200])\n",
      "6\n",
      "torch.Size([200, 1200])\n",
      "7\n",
      "torch.Size([200, 1200])\n",
      "8\n",
      "torch.Size([200, 1200])\n",
      "9\n",
      "torch.Size([200, 1200])\n",
      "10\n",
      "torch.Size([200, 1200])\n",
      "11\n",
      "torch.Size([200, 1200])\n",
      "12\n",
      "torch.Size([200, 1200])\n",
      "13\n",
      "torch.Size([200, 1200])\n",
      "14\n",
      "torch.Size([200, 1200])\n",
      "15\n",
      "torch.Size([200, 1200])\n",
      "16\n",
      "torch.Size([200, 1200])\n",
      "17\n",
      "torch.Size([200, 1200])\n",
      "18\n",
      "torch.Size([200, 1200])\n",
      "19\n",
      "torch.Size([200, 1200])\n",
      "20\n",
      "torch.Size([200, 1200])\n",
      "21\n",
      "torch.Size([200, 1200])\n",
      "22\n",
      "torch.Size([200, 1200])\n",
      "23\n",
      "torch.Size([200, 1200])\n",
      "24\n",
      "torch.Size([200, 1200])\n",
      "25\n",
      "torch.Size([200, 1200])\n",
      "26\n",
      "torch.Size([200, 1200])\n",
      "27\n",
      "torch.Size([200, 1200])\n",
      "28\n",
      "torch.Size([200, 1200])\n",
      "29\n",
      "torch.Size([200, 1200])\n",
      "[tensor([[-0.6626,  0.2374,  0.6261,  ...,  0.3751,  0.3939, -0.6425],\n",
      "        [-0.2512,  0.0597, -0.3330,  ..., -0.9362,  0.5731, -0.5963],\n",
      "        [-0.4618,  0.3530, -0.1260,  ...,  0.4963,  0.8653,  0.0105],\n",
      "        ...,\n",
      "        [ 0.1360,  0.3845, -0.6410,  ..., -0.8255,  0.4811, -0.0565],\n",
      "        [ 0.7990,  0.6711, -0.2315,  ..., -0.2540,  0.3819,  0.8345],\n",
      "        [ 0.1010,  0.0345,  0.3719,  ..., -0.7813, -0.0807, -0.0853]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.7711,  0.9208, -0.4777,  ..., -0.9347, -0.6538,  0.3698],\n",
      "        [ 0.2291, -0.5076, -0.6772,  ..., -0.9289, -0.3717,  0.3495],\n",
      "        [-0.2820,  0.7933, -0.3340,  ...,  0.7964, -0.9844,  0.5987],\n",
      "        ...,\n",
      "        [ 0.0648,  0.4054, -0.0807,  ...,  0.2576, -0.1618,  0.1561],\n",
      "        [ 0.1046,  0.3709,  0.1581,  ...,  0.3837,  0.6829, -0.1120],\n",
      "        [-0.1326, -0.0546,  0.0129,  ..., -0.1703, -0.7749, -0.0560]],\n",
      "       grad_fn=<SelectBackward>), tensor([[-0.4180,  0.1211,  0.4027,  ..., -0.3558, -0.4477, -0.0152],\n",
      "        [-0.1487,  0.1279,  0.5517,  ..., -0.0468, -0.7460,  0.8237],\n",
      "        [-0.1911, -0.2258, -0.0977,  ...,  0.2573,  0.1347,  0.7498],\n",
      "        ...,\n",
      "        [-0.7886,  0.2442,  0.3031,  ..., -0.8541, -0.6247, -0.0879],\n",
      "        [ 0.9098, -0.0272,  0.4270,  ...,  0.0112, -0.8249,  0.2527],\n",
      "        [ 0.7743,  0.8958, -0.8529,  ..., -0.4742,  0.0806,  0.5177]],\n",
      "       grad_fn=<SelectBackward>), tensor([[-0.9110, -0.2232,  0.7907,  ..., -0.7911,  0.4099,  0.9690],\n",
      "        [ 0.6829,  0.0058, -0.4395,  ...,  0.7301, -0.6560,  0.7873],\n",
      "        [ 0.7382,  0.1104, -0.3552,  ..., -0.9388,  0.0833, -0.0705],\n",
      "        ...,\n",
      "        [-0.8559, -0.7365, -0.1649,  ..., -0.4521, -0.8064,  0.2006],\n",
      "        [ 0.5715,  0.1736, -0.1071,  ..., -0.8263,  0.1208, -0.0652],\n",
      "        [ 0.9191, -0.0783,  0.0368,  ..., -0.1143,  0.8154,  0.1489]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.6916, -0.2504, -0.4609,  ...,  0.5011,  0.5766, -0.0849],\n",
      "        [ 0.5404,  0.0767,  0.7388,  ..., -0.7990,  0.4308,  0.4908],\n",
      "        [-0.0714, -0.1422, -0.2347,  ...,  0.7386, -0.8361,  0.5086],\n",
      "        ...,\n",
      "        [ 0.4747,  0.0838, -0.8416,  ..., -0.9867, -0.5758, -0.2520],\n",
      "        [ 0.8925,  0.1091,  0.1116,  ..., -0.4684,  0.3757, -0.1198],\n",
      "        [-0.3366,  0.1499,  0.0741,  ...,  0.7351, -0.4143,  0.5222]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.6204,  0.2974,  0.1326,  ..., -0.2996, -0.3797,  0.1036],\n",
      "        [-0.6250,  0.3254,  0.0395,  ..., -0.7469,  0.1359,  0.7421],\n",
      "        [ 0.6313,  0.0852,  0.2542,  ...,  0.7843,  0.2175,  0.3513],\n",
      "        ...,\n",
      "        [ 0.8471,  0.6498, -0.5139,  ...,  0.3475, -0.6464,  0.3737],\n",
      "        [-0.8563, -0.5124,  0.0730,  ..., -0.1894, -0.2537, -0.1002],\n",
      "        [-0.0366,  0.4127, -0.3035,  ..., -0.3603, -0.7638, -0.0325]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 8.5375e-01,  1.4234e-01, -3.1735e-01,  ...,  9.8544e-01,\n",
      "         -5.7112e-01,  3.5776e-01],\n",
      "        [-3.3979e-01,  9.4682e-02,  2.7540e-01,  ...,  4.1821e-01,\n",
      "         -7.4945e-01,  1.3084e-01],\n",
      "        [ 6.7288e-01,  7.9113e-02, -2.0055e-01,  ...,  1.2192e-01,\n",
      "         -2.4349e-01,  9.7276e-02],\n",
      "        ...,\n",
      "        [ 9.0275e-01,  6.2358e-04, -5.2576e-01,  ..., -5.3142e-01,\n",
      "         -2.1253e-01, -3.0591e-01],\n",
      "        [-3.7124e-01,  9.4317e-03,  1.1048e-02,  ..., -7.2789e-01,\n",
      "         -1.8145e-01, -6.8753e-02],\n",
      "        [ 7.1125e-01, -2.0004e-01,  5.5151e-01,  ...,  1.9069e-01,\n",
      "         -2.8869e-01,  8.2812e-01]], grad_fn=<SelectBackward>), tensor([[ 0.7817,  0.2190, -0.2526,  ..., -0.7515,  0.0066, -0.1643],\n",
      "        [-0.5959, -0.0759, -0.1996,  ..., -0.9859,  0.8725, -0.6396],\n",
      "        [ 0.9881, -0.1790, -0.3165,  ..., -0.9683, -0.7667,  0.1342],\n",
      "        ...,\n",
      "        [ 0.9650, -0.1584,  0.7172,  ..., -0.4524, -0.7690, -0.7841],\n",
      "        [-0.2822,  0.2625, -0.5267,  ...,  0.7413, -0.2336,  0.2309],\n",
      "        [ 0.9276, -0.3277,  0.1937,  ...,  0.6536, -0.7390,  0.1308]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 3.0729e-01, -1.1825e-01, -8.5576e-02,  ..., -5.6526e-01,\n",
      "          9.2380e-01, -1.0018e-01],\n",
      "        [ 4.7210e-01, -2.7990e-01,  3.5643e-01,  ..., -3.7345e-01,\n",
      "          7.3570e-01, -7.2583e-01],\n",
      "        [-4.0729e-01,  1.3148e-01, -1.4167e-01,  ..., -9.3724e-01,\n",
      "         -4.9745e-01, -4.9718e-01],\n",
      "        ...,\n",
      "        [ 3.7485e-01,  1.2243e-04, -7.6965e-02,  ..., -5.4600e-01,\n",
      "          3.1435e-01,  6.1916e-01],\n",
      "        [ 7.7573e-01, -1.6872e-01, -3.8244e-02,  ..., -7.7890e-01,\n",
      "         -2.5094e-01, -8.9837e-02],\n",
      "        [ 3.4213e-01, -2.5186e-01, -4.7013e-01,  ..., -5.7971e-01,\n",
      "          2.9106e-01, -5.2074e-02]], grad_fn=<SelectBackward>), tensor([[ 9.3584e-01,  4.3781e-01, -6.6312e-02,  ..., -9.7263e-01,\n",
      "          3.6777e-01,  1.4440e-01],\n",
      "        [-4.8462e-01,  3.0150e-01, -2.3453e-01,  ...,  7.2455e-01,\n",
      "         -4.8501e-01,  1.7226e-01],\n",
      "        [-9.9711e-02,  2.7524e-01,  3.9091e-01,  ...,  9.9811e-01,\n",
      "          3.4907e-01,  8.9306e-04],\n",
      "        ...,\n",
      "        [ 1.1931e-01, -2.8120e-01,  3.6955e-01,  ...,  4.1462e-02,\n",
      "         -2.5929e-01, -1.1998e-01],\n",
      "        [ 6.7622e-01,  3.6311e-01,  1.4846e-01,  ..., -7.3240e-01,\n",
      "          4.2728e-01,  2.6634e-01],\n",
      "        [ 8.2683e-02, -9.4817e-02, -5.2719e-01,  ..., -9.1870e-01,\n",
      "         -5.2226e-01,  5.7006e-01]], grad_fn=<SelectBackward>), tensor([[-0.3638, -0.6155, -0.2870,  ...,  0.8485,  0.7665, -0.4638],\n",
      "        [ 0.1476,  0.0591,  0.3469,  ...,  0.8587,  0.3429,  0.1790],\n",
      "        [ 0.1529,  0.0368,  0.8709,  ...,  0.7542, -0.0543,  0.5098],\n",
      "        ...,\n",
      "        [-0.7383, -0.3875, -0.2767,  ..., -0.9630,  0.1581, -0.0164],\n",
      "        [ 0.1772, -0.0745, -0.6096,  ..., -0.3110, -0.7198, -0.0785],\n",
      "        [ 0.6377,  0.0398, -0.0560,  ..., -0.7017, -0.7935, -0.2547]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.7833, -0.5713,  0.1841,  ..., -0.9318, -0.3939,  0.5913],\n",
      "        [ 0.5846,  0.4538,  0.3617,  ...,  0.9419,  0.7082,  0.9426],\n",
      "        [-0.6611, -0.5131, -0.1216,  ...,  0.9050,  0.0917,  0.2177],\n",
      "        ...,\n",
      "        [-0.0800,  0.0395, -0.2401,  ..., -0.3930, -0.8472,  0.6363],\n",
      "        [ 0.3025,  0.0490, -0.0920,  ..., -0.6000, -0.1364,  0.2250],\n",
      "        [ 0.4627,  0.1103,  0.0904,  ..., -0.0992,  0.2456,  0.1736]],\n",
      "       grad_fn=<SelectBackward>), tensor([[-0.0118, -0.1116, -0.3135,  ..., -0.9589,  0.2467,  0.2062],\n",
      "        [-0.7548, -0.2661, -0.2078,  ..., -0.7612, -0.7816,  0.1203],\n",
      "        [ 0.5193,  0.1341,  0.0033,  ...,  0.6498, -0.7685, -0.0812],\n",
      "        ...,\n",
      "        [-0.0090,  0.1320,  0.6343,  ..., -0.3226, -0.1365,  0.4383],\n",
      "        [ 0.4958, -0.3524,  0.0161,  ...,  0.2980, -0.5673, -0.0615],\n",
      "        [ 0.3957,  0.0224, -0.1047,  ...,  0.3251,  0.3685, -0.0527]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.6843, -0.0036,  0.0644,  ...,  0.9063,  0.3702,  0.1489],\n",
      "        [ 0.3194, -0.5525, -0.4925,  ..., -0.4939, -0.5148,  0.4606],\n",
      "        [-0.0219, -0.7283,  0.0595,  ..., -0.3365, -0.9251,  0.1059],\n",
      "        ...,\n",
      "        [ 0.6877,  0.2957,  0.0128,  ..., -0.1785,  0.2320, -0.1369],\n",
      "        [ 0.1866,  0.0733,  0.0144,  ...,  0.0998,  0.5894, -0.0413],\n",
      "        [ 0.7351,  0.1189,  0.0034,  ...,  0.5308,  0.1620,  0.2379]],\n",
      "       grad_fn=<SelectBackward>), tensor([[-0.5662, -0.4945, -0.3489,  ..., -0.7063,  0.2434, -0.1122],\n",
      "        [ 0.6538, -0.7293, -0.3494,  ...,  0.5590, -0.8396,  0.2118],\n",
      "        [ 0.9160, -0.4192,  0.0020,  ..., -0.5640,  0.5923, -0.1169],\n",
      "        ...,\n",
      "        [-0.1074, -0.8010, -0.4286,  ...,  0.6217, -0.1702,  0.7197],\n",
      "        [-0.3547,  0.1222,  0.1529,  ...,  0.4959,  0.9033, -0.0706],\n",
      "        [ 0.1951,  0.6395,  0.0039,  ..., -0.9620, -0.0197, -0.0543]],\n",
      "       grad_fn=<SelectBackward>), tensor([[-0.1468, -0.0029,  0.0144,  ...,  0.1618,  0.6257, -0.1254],\n",
      "        [-0.0706,  0.5569,  0.2973,  ..., -0.7374, -0.8605, -0.3450],\n",
      "        [ 0.8302, -0.0050, -0.3503,  ...,  0.3944, -0.6175,  0.2363],\n",
      "        ...,\n",
      "        [ 0.3982, -0.0984, -0.1577,  ..., -0.9048, -0.5871, -0.0181],\n",
      "        [ 0.7477, -0.3983, -0.4939,  ..., -0.7228, -0.9752, -0.8480],\n",
      "        [ 0.3252, -0.0263, -0.4571,  ..., -0.4289, -0.6403,  0.6159]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.6071,  0.2572,  0.7944,  ...,  0.0042, -0.5873,  0.0477],\n",
      "        [ 0.9354, -0.1531, -0.0026,  ...,  0.9950, -0.3573, -0.1248],\n",
      "        [ 0.9252, -0.2150, -0.7449,  ..., -0.9339,  0.7383, -0.7243],\n",
      "        ...,\n",
      "        [ 0.5525,  0.2283,  0.0116,  ..., -0.3239,  0.7439, -0.1252],\n",
      "        [ 0.2854,  0.0026,  0.0135,  ..., -0.8708,  0.0937, -0.0743],\n",
      "        [ 0.8806, -0.8437,  0.7132,  ..., -0.9890,  0.8858, -0.4404]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.4585,  0.7468, -0.5904,  ...,  0.9737,  0.7702,  0.3308],\n",
      "        [-0.7680, -0.0319, -0.0564,  ...,  0.4948, -0.3703, -0.1525],\n",
      "        [-0.7530,  0.0220, -0.0022,  ...,  0.3311, -0.3080, -0.1069],\n",
      "        ...,\n",
      "        [ 0.9547, -0.4047,  0.3223,  ..., -0.5017,  0.7070,  0.2481],\n",
      "        [ 0.9785, -0.0417,  0.0596,  ..., -0.0101, -0.7036, -0.0913],\n",
      "        [ 0.7884, -0.4163,  0.2255,  ..., -0.8996, -0.2614,  0.0580]],\n",
      "       grad_fn=<SelectBackward>), tensor([[-0.3424, -0.1984, -0.1170,  ..., -0.3323,  0.7136,  0.7178],\n",
      "        [ 0.7965, -0.4837,  0.6947,  ..., -0.0958,  0.0271, -0.4096],\n",
      "        [-0.7637,  0.4010, -0.5620,  ..., -0.8204, -0.3974, -0.1057],\n",
      "        ...,\n",
      "        [-0.9175, -0.0033,  0.0690,  ..., -0.7901,  0.3382, -0.1072],\n",
      "        [ 0.3087, -0.7094,  0.1345,  ..., -0.5558,  0.4404, -0.0820],\n",
      "        [-0.4709, -0.2454, -0.2079,  ...,  0.2427, -0.4930,  0.4781]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.1027,  0.0928,  0.0119,  ..., -0.9834,  0.2406, -0.1252],\n",
      "        [-0.2809, -0.0067,  0.0140,  ...,  0.9290,  0.8318, -0.1254],\n",
      "        [ 0.9648,  0.1692,  0.1036,  ..., -0.7776,  0.5882, -0.0972],\n",
      "        ...,\n",
      "        [-0.7703, -0.1623, -0.2813,  ..., -0.1888, -0.3526, -0.0400],\n",
      "        [ 0.1608, -0.2785,  0.0631,  ..., -0.8852, -0.6724,  0.0623],\n",
      "        [-0.3269, -0.0367,  0.8790,  ..., -0.8207,  0.4577,  0.6191]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.9393, -0.0030,  0.0139,  ..., -0.9233,  0.8327, -0.1254],\n",
      "        [ 0.6181, -0.6780,  0.0321,  ...,  0.1975, -0.8708, -0.1213],\n",
      "        [ 0.1257,  0.4990,  0.8572,  ..., -0.7486,  0.3823,  0.5591],\n",
      "        ...,\n",
      "        [-0.8019,  0.0357, -0.0781,  ..., -0.2215, -0.8086,  0.0992],\n",
      "        [ 0.5186, -0.2444,  0.2187,  ..., -0.9237, -0.6122, -0.1017],\n",
      "        [-0.3899,  0.0778,  0.3641,  ..., -0.9770, -0.2754, -0.1178]],\n",
      "       grad_fn=<SelectBackward>), tensor([[-0.3354,  0.1469, -0.1694,  ..., -0.6850,  0.4741, -0.0099],\n",
      "        [ 0.1230,  0.8661,  0.0592,  ...,  0.6142,  0.2420, -0.0517],\n",
      "        [ 0.9876, -0.1667, -0.1144,  ..., -0.5425, -0.3073,  0.4355],\n",
      "        ...,\n",
      "        [-0.5994,  0.0302, -0.2741,  ...,  0.7889,  0.0268,  0.9541],\n",
      "        [-0.7893,  0.1423,  0.1845,  ..., -0.0106,  0.7774,  0.9727],\n",
      "        [ 0.8490, -0.7443,  0.0986,  ..., -0.5218,  0.5270, -0.2067]],\n",
      "       grad_fn=<SelectBackward>), tensor([[-0.1588, -0.6793,  0.4384,  ...,  0.1572, -0.8878, -0.1314],\n",
      "        [ 0.3518,  0.1978,  0.2052,  ...,  0.2005, -0.5882,  0.5157],\n",
      "        [-0.3335,  0.1701, -0.5449,  ...,  0.8210,  0.7653,  0.1380],\n",
      "        ...,\n",
      "        [ 0.9389,  0.1484,  0.6755,  ...,  0.9682, -0.2366, -0.1307],\n",
      "        [ 0.9150, -0.0030,  0.0145,  ..., -0.7354, -0.8699, -0.1255],\n",
      "        [ 0.5678,  0.3137, -0.3449,  ..., -0.1492, -0.0362,  0.3589]],\n",
      "       grad_fn=<SelectBackward>), tensor([[-0.4308, -0.4695,  0.0891,  ..., -0.7755,  0.2194,  0.2274],\n",
      "        [-0.8042, -0.4651, -0.2515,  ..., -0.8827, -0.7407,  0.1128],\n",
      "        [ 0.7945, -0.1605, -0.6773,  ..., -0.9192,  0.2186,  0.4512],\n",
      "        ...,\n",
      "        [-0.2817,  0.1636, -0.1796,  ..., -0.7313, -0.9180, -0.0444],\n",
      "        [-0.6417,  0.4747, -0.0358,  ..., -0.9846, -0.3377, -0.0978],\n",
      "        [ 0.0435, -0.0827, -0.4623,  ..., -0.6393,  0.2081, -0.1198]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.2049, -0.3044, -0.6693,  ..., -0.8925,  0.1613,  0.5544],\n",
      "        [ 0.6073, -0.5497, -0.3165,  ..., -0.2420,  0.6534,  0.4044],\n",
      "        [ 0.8261, -0.1734,  0.1300,  ..., -0.0709, -0.9164, -0.1765],\n",
      "        ...,\n",
      "        [-0.2954,  0.2863,  0.7198,  ...,  0.1748,  0.1730,  0.7742],\n",
      "        [-0.5010, -0.2046,  0.0105,  ...,  0.8272,  0.2827, -0.0519],\n",
      "        [-0.3885,  0.4713,  0.0659,  ..., -0.1171, -0.8859, -0.4327]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.0187, -0.0475,  0.0542,  ..., -0.0817, -0.1248, -0.0270],\n",
      "        [-0.3433,  0.3412,  0.0364,  ...,  0.4207, -0.6625,  0.8941],\n",
      "        [ 0.1636, -0.0142, -0.4249,  ...,  0.8157, -0.5043, -0.0704],\n",
      "        ...,\n",
      "        [ 0.4982,  0.1552,  0.3703,  ...,  0.8604, -0.4022,  0.6580],\n",
      "        [-0.2717,  0.2022, -0.5236,  ..., -0.7554,  0.6480, -0.1102],\n",
      "        [ 0.8875,  0.2091,  0.0464,  ...,  0.8706, -0.3731, -0.0923]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.7358,  0.0063,  0.4303,  ..., -0.7907,  0.9401, -0.0671],\n",
      "        [ 0.9436,  0.3365,  0.6121,  ...,  0.6852, -0.1165,  0.0343],\n",
      "        [-0.9346,  0.1499,  0.5977,  ..., -0.3140,  0.5881,  0.7303],\n",
      "        ...,\n",
      "        [ 0.7074,  0.1096, -0.1293,  ...,  0.8774, -0.6954, -0.0497],\n",
      "        [-0.5685,  0.7593,  0.0287,  ..., -0.7126, -0.5318,  0.3862],\n",
      "        [ 0.3143, -0.0029,  0.0128,  ..., -0.5053,  0.9667, -0.1254]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.9531, -0.3517, -0.6664,  ...,  0.5435, -0.5718, -0.5327],\n",
      "        [-0.6390,  0.0421, -0.2100,  ..., -0.9568,  0.0432, -0.1545],\n",
      "        [ 0.9492, -0.4395, -0.2841,  ...,  0.3148, -0.8848, -0.0325],\n",
      "        ...,\n",
      "        [ 0.8553, -0.0023, -0.0095,  ..., -0.9069,  0.2457, -0.1194],\n",
      "        [ 0.0800,  0.5645,  0.1551,  ...,  0.7855, -0.3236, -0.0617],\n",
      "        [-0.1204, -0.4703,  0.0644,  ..., -0.2036, -0.3966, -0.1253]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.7278,  0.3809,  0.2070,  ..., -0.5617, -0.9721,  0.2570],\n",
      "        [ 0.4677, -0.2064, -0.9422,  ..., -0.5193,  0.1151, -0.0388],\n",
      "        [ 0.9759,  0.1081, -0.5792,  ...,  0.5704, -0.8507, -0.3734],\n",
      "        ...,\n",
      "        [-0.0440,  0.6947,  0.1932,  ...,  0.9447, -0.3452,  0.3811],\n",
      "        [ 0.4806,  0.0029,  0.4125,  ..., -0.7960,  0.6960,  0.2787],\n",
      "        [-0.3793, -0.1297,  0.0029,  ..., -0.8863,  0.7023, -0.1258]],\n",
      "       grad_fn=<SelectBackward>), tensor([[ 0.3132, -0.1246,  0.1301,  ..., -0.9004,  0.2482, -0.0096],\n",
      "        [ 0.3183, -0.1295, -0.1434,  ..., -0.4586,  0.8442,  0.2184],\n",
      "        [ 0.0288, -0.2185,  0.0150,  ..., -0.4177,  0.2622, -0.1221],\n",
      "        ...,\n",
      "        [ 0.2449, -0.2217,  0.0503,  ..., -0.7571, -0.6775,  0.2413],\n",
      "        [-0.8398, -0.0030,  0.0142,  ...,  0.4947, -0.3623, -0.1254],\n",
      "        [-0.5436,  0.0628, -0.0671,  ..., -0.2584, -0.0037,  0.2446]],\n",
      "       grad_fn=<SelectBackward>)]\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "save_loc_encoder = \"./saved_models/skip-best\".format(lr, VOCAB_SIZE)\n",
    "# mod = TheModelClass(*args, **kwargs)\n",
    "mod.load_state_dict(torch.load(save_loc_encoder))\n",
    "\n",
    "# sentences, lengths = d.fetch_batch(200)\n",
    "# output, _= mod.encoder.forward(sentences)\n",
    "output=[]\n",
    "sentencetotal=[]\n",
    "#print(output.shape)\n",
    "for i in range(0, 30):\n",
    "    sentences, lengths = d.fetch_batch(200)\n",
    "    #print(sentences[0].shape)\n",
    "    outputnow, _= mod.encoder.forward(sentences)\n",
    "    print(i)\n",
    "    print(outputnow.shape)\n",
    "    sentencetotal.append(sentences)\n",
    "    output.append(outputnow)#output is a list of 2Dtensors here\n",
    "#print(sentencetotal[1].shape)\n",
    "print(output)\n",
    "# print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "he asked as the two constables lifted the dazed Dorchester between them. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "1\n",
      "UNK Brammer UNK in to UNK the rising tension. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "2\n",
      "I was trying to say I wish I hadnt gotten mad at him so much those last few days. She stood clutching the dog, breathing slowly. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "3\n",
      "Nan rolled her eyes and held up two fingers. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "4\n",
      "She had burned her bridges, and burned them badly. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "5\n",
      "He rose and greeted me with a dashing smile that I couldn't help but return, despite my UNK stomach. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "6\n",
      "I ought to be more afraid of him. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "7\n",
      "The waiter retreated and Mr. Glass sat forward. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "8\n",
      "He wore a uniform with UNK decorated UNK and a cap hung on a hook beside another portrait of the queen. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "9\n",
      "Im sure we will, she replied. EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#print(sentences.shape)\n",
    "string = [\"he ran his hand inside his coat , double-checking that the unopened letter was still there ..\"\n",
    ",         \"im sure youll have a glamorous evening , she said , giving an exaggerated wink\"\n",
    ",         \"I was trying to decide if it was unseemly to drink tea alone with a strange gentleman in a salubrious hotel, and if I cared about that sort of thing anymore, when Eddie took advantage of my silence.\"\n",
    ",         \"Savannah flipped her blonde hair and physically stepped between Claire and Brody, her nose turned up in challenge.\"\n",
    ",         \"She had done it without thinking, even though she wasn't very strong, and now she gritted her teeth as she slammed into the railing, which caused her to cry out in pain.\"\n",
    ",         \"He sounded bored, but that could have been a result of his accent.\"\n",
    ",         \"I ought to have been frightened witless, but their light-hearted banter quelled my fear\"\n",
    ",         \"The brown eyes briefly flared and a small smile touched his lips.\"\n",
    ",         \"He wore a well-tailored black suit, untroubled by his impressive frame, a silk hat and gray silk tie.\"\n",
    ",         \"Im sure well be fine. She bit her lip, and I knew she was trying hard not to smile.\"]\n",
    "for j in range(10):\n",
    "    print(j)\n",
    "    query= d.convert_sentence_to_indices(string[j])\n",
    "    #print(query.shape)\n",
    "    query,_= mod.encoder.forward(query.reshape(1,MAXLEN))\n",
    "    #print(sentence.shape)\n",
    "    #print(query[0].shape)\n",
    "    cosine=[]\n",
    "    newsen=[]\n",
    "    for batch in output:\n",
    "        for sentence in batch:\n",
    "            #print(sentence.shape)\n",
    "            newsen.append(sentence)\n",
    "            cosine.append(torch.nn.functional.cosine_similarity(query[0],sentence,dim=0))\n",
    "    \n",
    "    #print(len(cosine))\n",
    "    \n",
    "    #i=max(cosine)\n",
    "    i=cosine.index(max(cosine))\n",
    "    #print(i)\n",
    "    #print(newsen[1].tolist())\n",
    "    #print(len(newsen))\n",
    "    actual=sentencetotal[i//200]\n",
    "    \n",
    "    print(d.convert_indices_to_sentences(actual[i%200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
